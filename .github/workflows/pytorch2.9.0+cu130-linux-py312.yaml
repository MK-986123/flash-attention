name: Build Flash Attention Wheel (Ultra-Parallel, GitHub Actions, September 2025)

on:
  workflow_dispatch:
  push:
    tags:
      - "v*"

permissions:
  contents: write

jobs:
  build-wheel:
    runs-on: ubuntu-latest
    env:
      PYTHON_VERSION: "3.12"
      CUDA_VERSION: "13.0.0"
      CUDNN_VERSION: "9.0"  # Added CUDNN version
      CXX11_ABI: "1"
      TORCH_CUDA_ARCH_LIST: "8.9" # Ada Lovelace (RTX 40 series)
      MAX_JOBS: "4"
      NVCC_THREADS: "4"
      _GLIBCXX_USE_CXX11_ABI: "1"
      TORCH_WHEEL_URL: "https://download.pytorch.org/whl/nightly/cu130/torch-2.9.0.dev20250903%2Bcu130-cp312-cp312-manylinux_2_28_x86_64.whl"

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: pip

      - name: Cache pip packages and wheels
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pip
            ./dist/*.whl
          key: ${{ runner.os }}-pip-py${{ env.PYTHON_VERSION }}-torch-2.9.0.dev20250903-cu130
          restore-keys: |
            ${{ runner.os }}-pip-py${{ env.PYTHON_VERSION }}-

      - name: Free disk space
        run: |
          sudo rm -rf /usr/share/dotnet /opt/ghc /opt/hostedtoolcache/CodeQL || true
          sudo apt-get purge -y -f qt5-doc qtbase5-doc || true
          sudo docker image prune -af || true
          df -h

      - name: Set up max swap (Linux)
        uses: pierotofy/set-swap-space@v1.0
        with:
          swap-size-gb: 12

      - name: Install CUDA 13.0.0
        uses: Jimver/cuda-toolkit@v0.2.27
        with:
          cuda: "13.0.0"
          method: network

      - name: Install CUDNN 9
        run: |
          # Add NVIDIA repository (should already be added from CUDA installation)
          sudo apt-get update
          
          # Install CUDNN 9
          sudo apt-get install -y --no-install-recommends \
            libcudnn9 \
            libcudnn9-dev
          
          # Verify CUDNN installation
          ls -la /usr/lib/x86_64-linux-gnu/libcudnn*

      - name: Set CUDA and CUDNN environment variables
        run: |
          echo "CUDA_HOME=/usr/local/cuda-13.0" >> $GITHUB_ENV
          echo "LD_LIBRARY_PATH=/usr/local/cuda-13.0/lib64:/usr/lib/x86_64-linux-gnu:${LD_LIBRARY_PATH}" >> $GITHUB_ENV
          echo "PATH=/usr/local/cuda-13.0/bin:${PATH}" >> $GITHUB_ENV
          
          # Verify CUDA installation
          nvcc --version
          ls -la /usr/local/cuda-13.0/lib64/ | head
          
          # Create symlinks for CUDNN if needed
          if [ ! -f /usr/local/cuda-13.0/lib64/libcudnn.so.9 ] && [ -f /usr/lib/x86_64-linux-gnu/libcudnn.so.9 ]; then
            sudo ln -sf /usr/lib/x86_64-linux-gnu/libcudnn.so.9 /usr/local/cuda-13.0/lib64/libcudnn.so.9
          fi

      - name: Download and Install PyTorch
        run: |
          # First ensure pip is upgraded
          python -m pip install --upgrade pip setuptools wheel
          
          # Download the wheel without renaming it
          cd /tmp
          wget "${{ env.TORCH_WHEEL_URL }}"
          
          # Install the wheel directly from the downloaded file
          python -m pip install --no-deps /tmp/torch-2.9.0.dev20250903+cu130-cp312-cp312-manylinux_2_28_x86_64.whl
          
          # Now install additional PyTorch dependencies that might be needed
          python -m pip install typing_extensions sympy filelock fsspec

      - name: Validate PyTorch and CUDA
        run: |
          # Print key environment variables for debugging
          echo "LD_LIBRARY_PATH: ${LD_LIBRARY_PATH}"
          echo "CUDA_HOME: ${CUDA_HOME}"
          
          # Check if required libraries exist
          echo "CUDA Libraries:"
          find /usr -name "libcudnn.so.9" || echo "libcudnn.so.9 not found"
          find /usr -name "libcudart.so*" || echo "libcudart not found"
          
          # Try to import torch - this should work now with CUDNN installed
          python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}'); print(f'CUDA version: {torch.version.cuda}')"

      - name: Install build dependencies
        run: |
          python -m pip install --upgrade ninja cmake packaging pybind11

      - name: Build flash-attention wheel with verbose logging
        run: |
          # Export critical environment variables again to be sure
          export CUDA_HOME=/usr/local/cuda-13.0
          export LD_LIBRARY_PATH=/usr/local/cuda-13.0/lib64:/usr/lib/x86_64-linux-gnu:${LD_LIBRARY_PATH}
          export PATH=/usr/local/cuda-13.0/bin:${PATH}
          export TORCH_CUDA_ARCH_LIST="8.9"
          export _GLIBCXX_USE_CXX11_ABI="1"
          
          # Print critical build environment info
          echo "Build environment:"
          echo "CUDA_HOME: $CUDA_HOME"
          echo "LD_LIBRARY_PATH: $LD_LIBRARY_PATH"
          echo "TORCH_CUDA_ARCH_LIST: $TORCH_CUDA_ARCH_LIST"
          echo "Python: $(which python)"
          echo "NVCC: $(which nvcc)"
          
          # Build the wheel with maximum verbosity and save log
          python setup.py bdist_wheel --verbose 2>&1 | tee build.log
          
          # List the resulting wheel
          ls -la dist/

      - name: Upload build log
        uses: actions/upload-artifact@v4
        with:
          name: flash-attn-build-log-${{ env.PYTHON_VERSION }}-torch-2.9.0.dev20250903-cu130
          path: build.log
          if-no-files-found: error

      - name: Verify wheel contents
        run: |
          WHEEL_PATH=$(ls dist/*.whl)
          echo "Built wheel: $WHEEL_PATH"
          
          # Check what's inside the wheel
          python -m pip install wheel
          python -m wheel unpack $WHEEL_PATH -d /tmp/wheel-contents
          
          # Look for compiled extensions
          find /tmp/wheel-contents -name "*.so" | xargs ls -la
          
          # Try to install the wheel
          python -m pip install --force-reinstall $WHEEL_PATH
          python -c "import flash_attn; print(f'Flash Attention installed successfully: {flash_attn.__version__}')"

      - name: Upload wheel artifact
        uses: actions/upload-artifact@v4
        with:
          name: flash-attn-wheel
          path: dist/*.whl
          if-no-files-found: error
