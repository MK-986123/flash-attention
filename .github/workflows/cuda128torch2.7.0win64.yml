name: Build Windows wheels and upload to GitHub Releases

on:
  create:
    tags:
      - "v*"

jobs:
  build_windows_wheels:
    name: Build wheels on Windows
    runs-on: windows-2022
    strategy:
      fail-fast: false
      matrix:
        torch-version: ["2.6.0", "2.7.0", "2.8.0"]
        python-version: ["3.12"]
        cuda-version: ["12.8"]
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel packaging ninja
          python -m pip install cmake

      - name: Set CUDA environment for build
        run: |
          echo "CUDA_HOME=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.8" >> $GITHUB_ENV
          echo "PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.8\bin;$PATH" >> $GITHUB_ENV

      - name: Install PyTorch ${{ matrix.torch-version }} with CUDA 12.8
        run: |
          pip install --index-url https://download.pytorch.org/whl/cu128 torch==${{ matrix.torch-version }}
          python -c "import torch; print('Torch Version:', torch.__version__); print('CUDA:', torch.version.cuda)"

      - name: Checkout flash-attention
        run: |
          git clone https://github.com/Dao-AILab/flash-attention.git
          cd flash-attention
          git checkout v${{ github.ref_name }}

      - name: Build wheel
        run: |
          cd flash-attention
          set FLASH_ATTENTION_FORCE_BUILD=TRUE
          python setup.py bdist_wheel --dist-dir=dist
          dir dist

      - name: Upload to GitHub Release
        uses: softprops/action-gh-release@v1
        with:
          files: flash-attention/dist/*.whl
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
