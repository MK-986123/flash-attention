name: Test Windows CUDA ${{ matrix.cuda-version }} PyTorch ${{ matrix.torch-version }}

on:
  workflow_dispatch:
  pull_request:
    paths:
      - ".github/workflows/cuda128torch2.7.0win64.yml"
      - "setup.py"
      - "csrc/**"
      - "flash_attn/**"
      - "hopper/**"
      - "tests/**"
  push:
    branches:
      - main
    paths:
      - ".github/workflows/cuda128torch2.7.0win64.yml"
      - "setup.py"
      - "csrc/**"
      - "flash_attn/**"
      - "hopper/**"
      - "tests/**"

env:
  FLASH_ATTENTION_FORCE_BUILD_TRITON: 0
  FLASH_ATTENTION_SKIP_BUILD_API: 1
  MSVC_TOOLSET: "14.29" # VS 2019
  TORCH_VERSION: "2.7.0.dev20240507"
  TORCH_CUDA_VERSION: "cu121"
  CUDA_VERSION: "12.1.0"
  CUDA_VERSION_MM: "12.1"
  CUDA_VERSION_MM_USCORE: "12_1"
  CUDA_URL: "https://developer.download.nvidia.com/compute/cuda/12.1.0/local_installers/cuda_12.1.0_531.14_windows.exe"

jobs:
  build:
    runs-on: windows-2019
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.10"]

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Set up MSVC
        uses: ilammy/msvc-dev-cmd@v1
        with:
          arch: x64
          toolset: ${{ env.MSVC_TOOLSET }}

      - name: Install CUDA Toolkit
        shell: cmd
        run: |
          echo Installing CUDA %CUDA_VERSION%...
          curl -L -o cuda_installer.exe %CUDA_URL%
          cuda_installer.exe -s nvcc_%CUDA_VERSION_MM% cudart_%CUDA_VERSION_MM% nvrtc_%CUDA_VERSION_MM% nvtx_%CUDA_VERSION_MM% visual_studio_integration_%CUDA_VERSION_MM%
          echo Adding CUDA to PATH...
          echo C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v%CUDA_VERSION_MM%\bin >> %GITHUB_PATH%
          echo CUDA_PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v%CUDA_VERSION_MM% >> %GITHUB_ENV%
          echo CUDA_PATH_V%CUDA_VERSION_MM_USCORE%=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v%CUDA_VERSION_MM% >> %GITHUB_ENV%

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install Python Dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install packaging cmake wheel
          python -m pip install torch==${{ env.TORCH_VERSION }}+${{ env.TORCH_CUDA_VERSION }} \
            torchvision==0.22.0+${{ env.TORCH_CUDA_VERSION }} \
            torchaudio==2.7.0+${{ env.TORCH_CUDA_VERSION }} \
            --index-url https://download.pytorch.org/whl/nightly/${{ env.TORCH_CUDA_VERSION }}
          python -m pip install einops rotary-embedding-torch xformers==0.0.26

      - name: Build Wheel
        run: |
          pip wheel . -v --no-deps --no-clean --wheel-dir dist
        env:
          TORCH_CUDA_ARCH_LIST: "8.0;8.6;8.9;9.0"
          FLASH_ATTENTION_BUILD_VERBOSE: 1
          FLASH_ATTENTION_BUILD_HOPPER: 1
          FLASH_ATTENTION_SKIP_BUILD_WS: 1
          FLASH_ATTENTION_DISABLE_FA_TRITON: 1

      - name: Upload Built Wheel
        uses: actions/upload-artifact@v4
        with:
          name: flash-attn-win-cuda${{ env.CUDA_VERSION_MM }}-torch${{ env.TORCH_VERSION }}-py${{ matrix.python-version }}
          path: ./dist/*.whl
          retention-days: 7

      - name: Test Wheel
        shell: cmd
        run: |
          set FLASH_ATTENTION_DISABLE_FA_TRITON=1
          dir dist
          pip install dist\*.whl
          echo Running tests...
          pytest -q -s tests/test_flash_attn.py -k "not ck"
          pytest -q -s tests/test_rotary.py -k "not ck"
